# Как мониторить сотни инстансов PostgreSQL и не сойти с ума

## Введение и цели статьи (для кого она будет полезна и что даст читателю)
Читать 16 минут.

Если вы инженер (?) в крупной компании (особенно если ваша органищация поставляет свои услуги в виде SaaS решений), то вам так или иначе надо будет решать задачу мониторинга работы всех ваших PostgreSQL. Очень часто бывает так что на Postgre SQL завязан важный с т.з. финансовых рисков функционал в вашей организации, поэтому крайне желательно не только иметь монитринг, но и получать уведомления когда что-то идет не так (или предиктивно получать уведомления заранее, если что-то пойдет не так в самом ближайшем будущем).
В рамках статьи мы рассмотрим какими способами это можно организовать:
- Все самому с использованием уже ставшего стандартом стека Prometheus + Grafana (на котором можно будет в последующем строить мониторинг любых других ваших сервисов);
- Подключить opensorce сторонние специализированные решения для мониторинга PostgreSQL;
- Использовать специализированные платные решения;
По каждому варианту поймем все плюсы и минусы, чтобы вы могли объективно выбрать именно ваш путь.

## Все самому с помощью Prometheus + Grafana
На связке Prometheus с Grafana строят свои системы мониторинга большинство кампаний. Здесь основное преимущество в том, что есть готовые экспортеры в Prometheus для разных систем и можно быстро развивать и настраивать систему мониторинга подходящую под практически любые нужды. У вас не будет зоопарка разных инструментов, все консистентно и единообразно. Научившить один раз настраивать конфигурации описанные ниже вы сможете собирать мониторинг абсолютно любых систем и сервисов в вашей организации.

![Мониторинг PosgreSQL с Prometheus и Grafana](/images/prometheus.drawio.png)

Для того чтобы это настроить вам понадобится:
### 1. Установить и настроить postgresql_exporter на сервере PostgreSQL.
https://github.com/prometheus-community/postgres_exporter/  
По сути это агент, который будет собирать метрики PostgreSQL и отдавать их в Prometheus по локальному endpoint (далее Prometheus опрашивает этот адрес каждые n секунд и складывать в свою time series БД).

---
#### Принцип работы postgres_exporter (равно как и любых других экспортеров для Grafana)
##### Подключение к PG:
postgres_exporter подключается к PostgreSQL через стандартное подключение (обычно TCP-соединение через порт 5432) и гоняет к нему стандантные SQL запросы за метриками.
По правам он использует специально созданного PG пользователя с правами на чтение информации о состоянии сервера (например, членство в роли pg_monitor).
##### Сбор метрик:
postgres_exporter выполняет SQL-запросы к системным представлениям PostgreSQL (например, pg_stat_database, pg_stat_activity, pg_stat_replication, pg_stat_bgwriter, и т.д.).
Метрики, которые собираются, конвертируются в формат Prometheus.  
Здесь важно иметь в виду, что если не устанавливать в PG ряд дополнительных расширений, то набор метрик будет весьма скудным. Для сбора расширенной информации по метрикам, например по раздутию таблиц, работе индексов и пр. надо будет доставлять еще ряд расширений и дополнительно конфигурировать postgres_exporter. В частности полезно поставить следующие расширения:
- pg_stat_statements стандартное расширение для анализа производительности запросов и статистики;
- pg_buffercache для анализа буферов PostgreSQL;  

Надо иметь в виду, что установка дополнительных расширений будет, в определенных ситуациях, отжирать у вас ресурсы самого PostgreSQL, важно следить за этим.
Плюс простая установка этих расширений не приведет к тому что все необходимое начнет собирать сам postgres_exporter. Надо будет добавлять необходимые запросы в его конфигурации, что может отнять у вас дополнительное время.

##### Экспорт метрик:
Сервис postgres_exporter предоставляет HTTP-endpoint (/metrics), с которого Prometheus регулярно собирает метрики (scrape - т.н. скраппинг постоянны через n секунд).

> Похожим образом работают все другие виды экспортеров для prometheus. У Prometheus есть масса различных экспортеров для разных систем, в частности mysql_exporter, mongodb_exporter, redis_exporter и пр.

---  


> **Для сбора метрик самого хоста вам придется дополнительно установить и настроить node_exporter, который работает схожим образом**

Установив postgres_exporter надо настроить пользака, под которым будет происходить сбор метрик мониторинга:
```
CREATE USER postgres_exporter WITH PASSWORD '****';
ALTER USER postgres_exporter SET SEARCH_PATH TO postgres_exporter,pg_catalog;

-- Права доступа для пользователя мониторинга:
GRANT CONNECT ON DATABASE postgres TO postgres_exporter;
GRANT pg_monitor TO postgres_exporter;

```
Далее необходимо настроить запуск postgres_exporter в виде сервиса (systemd)

### 2. Настроить запуск postgres_exporter в виде сервиса (systemd):
Создаем файлик /etc/systemd/system/postgres_exporter.service:
```
[Unit]
Description=Prometheus PostgreSQL Exporter
Wants=network-online.target
After=network-online.target

[Service]
User=postgres
Group=postgres
Type=simple
ExecStart=/usr/local/bin/postgres_exporter \
  --web.listen-address=0.0.0.0:9187 \
  --web.telemetry-path=/metrics \
  --log.level=info \
  --extend.query-path=/etc/postgres_exporter/queries.yaml \
  DATA_SOURCE_NAME="postgresql://postgres_exporter:exporter_password@localhost:5432/postgres?sslmode=disable"

Restart=always

[Install]
WantedBy=multi-user.target

```
Запустите и добавьте в автозагрузку:

```
systemctl daemon-reload
systemctl start postgres_exporter
systemctl enable postgres_exporter
```
Проверьте доступность метрик по адресу:
http://<IP_postgres_exporter>:9187/metrics

### 3. Установить и настроить Prometheus:
Далее нам надо установить [Prometheus](https://prometheus.io/download/) и добавить наш endpoint exporter'а в его конфиг /etc/prometheus/prometheus.yml
```
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'postgres'
    static_configs:
      - targets: ['IP_postgres_exporter:9187']

```

Запускаем Prometheus и добавляет его в автозагрузку:
```
systemctl restart prometheus
systemctl enable prometheus
```

Приверить, что метрики собираются можно зайдя по адресу http://<IP_prometheus>:9090

### 4. Установка Grafana и подключение Prometheus как источника данных:
Следующим шагом требуется установить Grafana и подключить наш Prometheus как источник данных. Для этого:
1. Заходим в Grafana: http://<IP_grafana>:3000
2. Открываем раздел: 
```
Configuration → Data sources → Add data source → Prometheus
```
3. Указываем URL нашего Prometheus
```
http://<IP_prometheus>:9090
```

### 5. Добавим готовые дашборды PostgreSQL в Grafana:
Лучше взять готовые проверенные дашборды:
- Postgres Overview <https://grafana.com/grafana/dashboards/455-postgres-overview/>

![Дашборд Postgres Overview](/images/pg_overview.png)

- PostgreSQL Database <https://grafana.com/grafana/dashboards/9628-postgresql-database/>

![Дашборд PostgreSQL Database](/images/pg_database.png)

Выбираем понравившийся и в Grafana выбираем:

```
Dashboards → Import → вставь ID (9628 или 455) → выбери источник Prometheus.
```

### Минусы и плюсы такого решения
#### Плюсы
- Универсальность архитектуры мониторинга для любых ваших систем. Можно подключаться и мониторить практически все ваши системы в единой архитектуре;
- Можно добавлять новые готовые дашборды или создавать свои;
- Полная бесплатность;
- Индустриальный стандарт;
#### Минусы
- Сложность настройки;
- Нет предиктивной аналитики, вы можете оценивать состояние системы только на "сейчас";
- Нет возможности управления (даже минимальной);
- Нет встроенной аналитики по "тяжелым" запросам. Нет профилировщика таких запросов;

В целом такое решение пригодится только для самого базового мониторинга или для того, кто сам отличный DBA и знает как и что ему нужно добавить в стандартные метрики, чтобы собирать то что нужно.

*Так-же надо понимать какие вам нужны триггеры и оповещения (т.н. Alerting).*

Настраивать их можно как в Grafana ("Alert" → "Create alert rule" на панели) и указав запрос метрики:

```
avg(pg_stat_database_blks_hit / (pg_stat_database_blks_hit + pg_stat_database_blks_read))
```

Далее задать порог, длительность сколько держится условие, список получателей по email, Slack и пр.

Так-же алертинг можно настраивать в Prometheus. Визуально так сделать не получится. Придется прописывать все алерты в yaml файлике и подключать ссылку на него в prometheus.yml

## Готовые opensource решения
Кто не готов разбираться и настраивать все самостоятельно, получив на выходе достаточно скудный функционал, могут попробовать opensource решения разработанные именно для мониторинга PostgreSQL. Далее рассмотрим два самых популярных из них. На самом деле нормальных, развивающихся и бесплатных решений не очень много.

### Percona Monitoring and Management (PMM)

https://www.percona.com/software/database-tools/percona-monitoring-and-management 

Довольно мощное решение для мониторинга PostgreSQL (+ еще MySQL и MongoDB) с базовыми возможностями аналитики запросов, готовыми дашбордами, рекомендациями и аннотациями. Подходит для production-сред с потребностью в централизованном мониторинге и диагностике.

![Percona](/images/percona.png)

#### Архитектура: клиент‑серверная модель

 - PMM Client (устанавливается на каждом сервере с базой данных):
   - Включает pmm-agent (управляет процессами);
   - Экспортеры (например те самые postgres_exporter и node_exporter) для сбора метрик;
   - vmagent (отправка данных);

 - PMM Server (центральный сервер мониторинга):
   - Хранит метрики в VictoriaMetrics;
   - Хранит аналитические данные запросов в ClickHouse;
   - Визуализация и дашборды через Grafana с разработанными Percona шаблонами для нее (как веб морду использует Garafana, да);
   - Включает базовые Query Analytics (QAN) и Percona Advisors (рекомендации по производительности и безопасности);

![PMM Architecture](/images/pmm.png)

#### Возможности

|||
|---|---|
| Шаблонные дашборды Grafana для PostgreSQL | Включают все основные метрики: CPU, память, I/O, соединения, tuples, индексы, сетевой трафик, процессы и прочее ([подробнее](https://www.percona.com/software/database-tools/percona-monitoring-and-management/postgresql-monitoring)). |
| Анализ запросов      | Анализ SQL-запросов: медленные, ресурсоёмкие, с деталями EXPLAIN и историей выполнения ([подробнее](https://www.percona.com/blog/inspecting-mysql-servers-part-5-percona-monitoring-and-management/)). |
| Аннотации (Annotations)    | Удобная возможность вручную отмечать события (деплой, сбой и т.п.) прямо на графиках для анализа причин проблем ([подробнее](https://www.percona.com/software/database-tools/percona-monitoring-and-management/postgresql-monitoring?utm_source=chatgpt.com)). |
| Percona Advisors          | Автоматический анализ конфигураций и рекомендации по безопасности и производительности ([подробнее](https://www.percona.com/software/database-tools/percona-monitoring-and-management/postgresql-monitoring)). |
| Alerting & управление      | Настройка алертов, возможность бэкапов и восстановления ([подробнее](https://www.percona.com/software/database-tools/percona-monitoring-and-management)). |

#### Минусы и плюсы PMM
##### Плюсы
- "Из коробки" готовые расширенные дашборды для PostgreSQL;
- Включает Query Analytics и Advisors (этого нет в типовой связке Grafana + Prometheus);
- Масштабируемая архитектура;
- Гибкость установки через Docker, Helm и пр.
##### Минусы
- Больше компонентов, сложнее ментейнить все это;
- Менее универсально, только для 3 типов СУБД;
- Сложнее будет докрутить своими метриками по сравнению с Prometheus + Grafana;

### pgAdmin 4

https://www.pgadmin.org/

Не совсем система мониторинга и анализа, скорее веб-GUI для администрирования PostgreSQL (создание объектов, миграции, бэкапы, Query Tool), в котором есть базовые дашборды по состоянию сервера.
Он подходит скорее как удобная админка и точечный мониторинг «здесь-и-сейчас», но не является полноценной системой мониторинга/алертинга.

#### Архитектура

Python (Flask) + psycopg/libpq. Работает в двух режимах - Desktop приложуха и Server (веб-приложение). Данные для виджетов берёт на лету из стандартных pg_stat_* представлений и системных функций PostgreSQL. Метрики не накапливает - только опрашивает и показывает.

![PGAdmin 4 Architecture](/images/pg_admin_arch.png)

#### Возможности

|||
| --- | --- |
| Дашборды | «Живые» графики: CPU/IO wait (условное по PostgreSQL, а не хостовые), активные/idle сессии, число блокировок, tuples in/out, чекпоинты, WAL-активность. Данные берутся из `pg_stat_activity`, `pg_stat_database`, `pg_stat_bgwriter`, `pg_stat_replication` и др. |
| Activity / Locks / Sessions | Просмотр текущих запросов, планов, блокировок, ожиданий, отмена/terminate процессов. |
| Query Tool | SQL редактор, EXPLAIN/EXPLAIN ANALYZE, автоформатирование, история запросов. |
| Maintenance | VACUUM/REINDEX/ANALYZE/CLUSTER, бэкапы/восстановление (обёртки над `pg_dump/pg_restore`). |
| Управление СУБД | Роли/права, таблицы, индексы, партиции, расширения (в т.ч. `pg_stat_statements`). |
| Аутентификация/Роли в UI | Учетки самого pgAdmin, группы, хранение подключений, SSO (LDAP/OAuth) |

#### Минусы и плюсы pgAdmin 4
##### Плюсы
- Работа без агентов: подключается напрямую к PostgreSQL; достаточно сетевого доступа и ролей;
- Продвинутые админ функции: Query Tool, EXPLAIN, бэкапы, управление объектами и ролями;
- Простая установка: пакеты для Win/macOS/Linux, Docker-образ, Helm-чарт; работает и как Desktop, и как Web.
##### Минусы
- Нет никаких хостовых метрик т.е. аналитика совсем не полная;
- Не система мониторинга: нет долговременного хранения метрик/серий (показывают текущее/недавнее состояние, без ретроспективной аналитики)
- Нет алертинга, «предиктивной» аналитики, советников и готовых SLO/alerts;
- Ограниченные дашборды по сравнению с PMM/Grafana; нельзя «докрутить» экспортеры/свои метрики как в Prometheus.

В целом подходит для малых/средних инсталляций, где нет требований к ретроспективному мониторингу и алертингу, ну или использовать как дополнение к PMM/Prometheus-стэку если у вас есть желание городить зоопарк.

## Платные коммерческие решения

### pganalyze

https://pganalyze.com/

Позволяет проводить достаточно глубокую диагностику и оптимизацию подключенных СУБД. Основная цель - не просто показывать метрики, а автоматически собирать статистику и логи, находить проблемные запросы, давать рекомендации по индексам и обслуживанию (VACUUM/ANALYZE).

Есть два варианта поставки:
- SaaS (облачный сервис, в который отправляются данные);
- Enterprise Server (self-hosted) — чтобы поднять у себя.

Для сбора метрик используется свой open-source агент (устанавливается рядом с базой и пересылает статистику в pganalyze).

![pganalyze](/images/pganalyze.webp)

#### Архитектура

**Collector (open-source агент).** Устанавливается на каждом хосте с PostgreSQL. Собирает данные из:
- системных вьюх (pg_stat_statements, pg_stat_activity, pg_stat_bgwriter и др.),
- логов PostgreSQL (парсинг slow queries, ошибок, deadlocks),
- настроек конфигурации.

Передаёт всё это в сервис pganalyze (через TLS).

**pganalyze Backend (SaaS или self-hosted)**
- Хранит метрики и логи;
- Анализирует запросы, строит EXPLAIN-планы, выявляет узкие места;
- Генерирует советы: каких индексов не хватает, где нужен VACUUM, где проблема в конфигурации;
- Поддерживает OpenTelemetry для интеграции с APM/Observability-системами.

**Web UI (Dashboard).** Доступ через браузер. Есть готовые панели:
- метрики нагрузки (CPU/IO/locks/sessions),
- разбивка по запросам и их планам,
- Index Advisor, Vacuum Advisor,
- Log Insights (ошибки, deadlocks, медленные запросы). Можно настраивать алерты и интеграции в какой-нибуль Slack.

![pganalyze Architecture](/images/pganalyze_arch.png)

#### Возможности

|                            |                                                                                                      |
| -------------------------- | ---------------------------------------------------------------------------------------------------- |
| Дашборды      | Достаточно типовые графики.        |
| Профилирование производительности      | История выполнения запросов, EXPLAIN-планы, выявление самых «тяжёлых» и часто вызываемых SQL.        |
| Аналитика индексов          | Автоматические рекомендации по созданию индексов, включая оценку выигрыша в производительности.      |
| VACUUM/ANALYZE | Советует, когда таблицы раздуваются и нужен VACUUM, либо неправильно настроены автовакуум-параметры. |
| Анализ по логам          | Парсинг логов PostgreSQL: ошибки, deadlocks, statement timeouts, медленные запросы.                  |
| Проверка конфигурации   | Автоматическая проверка конфигурации PostgreSQL и советы по оптимизации.                             |
| Уведомления и интеграции | Уведомления в мессенджеры; интеграция с OpenTelemetry для других систем мониторинга.                        |


#### Минусы и плюсы pganalyze
##### Плюсы
- Хороший фокус на оптимизацию производительности: автоматические советы по индексам, VACUUM-советы, разбор запросов и логов;
- Collector - open source, легко внедрить и проверить;
- Поддержка как SaaS, так и self-hosted (кому-то может быть удобно в SaaS);
- Богатая встроенная аналитика, которой нет у классических Prometheus/Grafana-стэков.
##### Минусы
- Ориентирован только на PostgreSQL (в отличие от Percona PMM, который покрывает ещё MySQL и MongoDB);
- Нет такого широкого комьюнити, как у Grafana/Prometheus;
- Не понятно как приобрести и получать поддержку продукта в РФ (видимо пока никак);

В целом достаточно продвинутое и богатое решение с массой функционала которого нет у OpenSource вариантов.

### Tantor Platform

https://tantorlabs.ru/products/platform

Платформа для мониторинга и аналитики PostgreSQL корпоративного уровня. Цель - не просто отображать метрики, а комплексно управлять всем парком Postgres, собирать и хранить метрики БД и хостов, анализировать запросы и конфигурацию, автоматизировать обслуживание, выдавать рекомендации и централизовать оповещения. Поддерживает мульти-тенантность (тенанты/воркспейсы), роли и гибкое разграничение доступа.
Модель поставки: self-hosted (on-prem), планируется SaaS. Может быть развернута в отказоустойчивом и масштабируемом режиме.

![Tantor](/images/tantor.png)

#### Архитектура

**Агенты (на серверах с PostgreSQL).** Легковесные go процессы, которые:
- собирают метрики PostgreSQL из pg_stat_*, pg_stat_statements, событий/логов и т.д.;
- снимают хостовые метрики (CPU, RAM, диски, сеть);
- по командам выполняют операции обслуживания (VACUUM/ANALYZE, скрипты), применяют конфигурации;
- публикуют изменения метрик в шину сообщений.

**Шина сообщений (NATS).** Асинхронный обмен данными:
- topics/streams: metrics (телеметрия), commands (управляющие задания), events (события);
- развязка источников/потребителей, буферизация и горизонтальное масштабирование.

**Keeper (ingest/очереди метрик).**
Принимает и нормализует потоки метрик из NATS, агрегирует и записывает их в хранилище платформы.

**Backend (REST/WebSocket API).**
Бизнес-логика: каталог инстансов, дашборды, политика доступа, алерты, задания, интеграции. Отдаёт данные UI и управляет агентами (через NATS).

**PG Configurator (advice engine).**
Сервис рекомендаций по параметрам PostgreSQL, профилям нагрузки, VACUUM/AUTOVACUUM, настройкам памяти и I/O. Возвращает советы и готовые патчи конфигурации.

**OperDB (PostgreSQL, центральное хранилище).**
Хранит: метрики, события, конфигурации, модели воркспейсов/ролей, историю рекомендаций и выполненных задач. Доступ через PgBouncer.

**Web UI (SPA).**
Панели мониторинга, профили запросов, журнал событий, конструктор алертов, каталог БД, работа с воркспейсами/пользователями и пр.

**Интеграции.**
- Мессенджеры (Telegram, Mattermost, e-mail): доставка алертов/уведомлений;
- Triafly BI: экспорт исторических данных мониторинга для долговременной аналитики и построения произвольной отчетности;
- SIEM: отправка событий/инцидентов по Syslog (внешние SOC/SIEM).

![Tantor Architecture](/images/tantor_arch.png)

#### Возможности

|                                    |                                                                                                                                                                                   |
| ---------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Дашборды и метрики             | Готовые панели и огромная масса графиков по PostgreSQL и хосту: соединения, транзакции, hit-ratio, WAL/репликация, чекпоинты, блокировки; CPU/RAM/IO/FS/сеть. Агрегации и фильтры по воркспейсам/инстансам. |
| Профилирование запросов        | Вся история «тяжёлых» запросов, планы `EXPLAIN/ANALYZE`, деградации и регрессии по времени, рекомендации по оптимизации самих запросов. |
| Рекомендации (PG Configurator) | Советы по параметрам Postgres (shared\_buffers/work\_mem/автовакуум/IO), подсказки по VACUUM/ANALYZE и обслуживанию. |
| Управление конфигурацией       | Генерация патчей конфигурации, откат/применение через агентов, аудит изменений. |
| Операции обслуживания          | Удалённый запуск VACUUM/REINDEX/ANALYZE/скриптов, планировщик задач. |
| Мульти-тенантность             | Тенанты и воркспейсы: логическое разделение всех баз и прав доступа; удобная делегация ответственности командам. |
| RBAC и аудит                   | Роли (viewer/админ воркспейса/админ тинанта/system-admin), аудит действий и изменений каждым. |
| Алерты и политики              | Пороги/условия, подавление (silence), маршрутизация получателей по важности/тенанту, тестовые нотификации. |
| Интеграции                     | Мессенджеры (Telegram/e-mail), Triafly BI (экспорт для расширенной аналитики), SIEM (syslog). |
| API/Автоматизация              | Полный REST API (Swagger/OpenAPI) для интеграций, инфраструктурного кода и self-service сценариев. |
| HA                             | Поддержка кластерных развертываний всех компонентов системы; управление PostgreSQL-кластерами (Patroni), мониторинг репликации и failover-событий. |
| Кластеры                       | Управление и мониторинг кластерами Patroni |
| Безопасность/Compliance        | Изоляция доступов, возможность анонимизации данных (перед выгрузками), журнал событий. |
| Бекапирование                  | Интеграция с системами бекапирования Backman и RuBackup |


#### Минусы и плюсы Tantor Platform
##### Плюсы
- Есть темная тема 😃.
- Глубокая специализация именно под PostgreSQL: рекомендации по конфигурации, анализ планов, операции обслуживания и управление кластерами «из коробки».
- Единый стек: хранение, бизнес-логика и UI интегрированы; нет зависимости от внешних TSDB/Grafana/ClickHouse.
- Полные метрики: БД и ОС через агентов; асинхронная шина NATS обеспечивает масштабируемость и устойчивость к сбоям.
- Мульти-тенантность и RBAC: удобное разделение инфраструктуры по командам/проектам с прозрачным аудитом.
- Интеграции: мессенджеры, Triafly BI (для долгой истории/отчетности), SIEM (syslog) — без «самоделок».
- Разработчик в РФ, соответственно и поддержка для корпоративных клиентов;
- Уже встроенный продвинутый анализатор планов запросов Explain от Tensor https://explain.tensor.ru/ с подсказками что исправить в "проблемных" запросах/индексах
![Tantor 03](/images/tantor_03.jpg)

##### Минусы
- Только PostgreSQL: не универсальный мониторинг всех СУБД (в отличие от PMM).
- Требует агентов и нескольких сервисов: установка/операционка существенно сложнее, чем у простых дашбордов Grafana.
- Кастом-дашбордов нет: ориентирована на встроенные панели; гибкость ниже, чем у чистого Grafana-стека (зато меньше ручной настройки).

![Tantor 01](/images/tantor_01.png)

![Tantor 02](/images/tantor_02.png)

В целом это платформа уровня enterprise для эксплуатации PostgreSQL: централизует мониторинг, аналитику запросов и управление, снижает TTR за счёт рекомендаций с предиктивной аналитикой и автоматизации, хорошо вписывается в корпоративный ландшафт через интеграции и роли. Пожалуй наиболее продвинутое в плане функционала среди всех.