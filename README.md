# Как мониторить сотни инстансов PostgreSQL и не сойти с ума

## Введение и цели статьи (для кого она будет полезна и что даст читателю)
Читать 12 минут.

Если вы инженер (?) в крупной компании (особенно если ваша органищация поставляет свои услуги в виде SaaS решений), то вам так или иначе надо будет решать задачу мониторинга работы всех ваших PostgreSQL. Очень часто бывает так что на Postgre SQL завязан важный с т.з. финансовых рисков функционал в вашей организации, поэтому крайне желательно не только иметь монитринг, но и получать уведомления когда что-то идет не так (или предиктивно получать уведомления заранее, если что-то пойдет не так в самом ближайшем будущем).
В рамках статьи мы рассмотрим какими способами это можно организовать:
- Все самому с использованием уже ставшего стандартом стека Prometheus + Grafana (на котором можно будет в последующем строить мониторинг любых других ваших сервисов);
- Подключить opensorce сторонние специализированные решения для мониторинга PostgreSQL;
- Использовать специализированные платные решения;
По каждому варианту поймем все плюсы и минусы, чтобы вы могли объективно выбрать именно ваш путь.

## Все самому с помощью Prometheus + Grafana
На связке Prometheus с Grafana строят свои системы мониторинга большинство кампаний. Здесь основное преимущество в том, что есть готовые экспортеры в Prometheus для разных систем и можно быстро развивать и настраивать систему мониторинга подходящую под практически любые нужды. У вас не будет зоопарка разных инструментов, все консистентно и единообразно. Научившить один раз настраивать конфигурации описанные ниже вы сможете собирать мониторинг абсолютно любых систем и сервисов в вашей организации.

![Мониторинг PosgreSQL с Prometheus и Grafana](/images/prometheus.drawio.png)

Для того чтобы это настроить вам понадобится:
### 1. Установить и настроить postgresql_exporter на сервере PostgreSQL.
https://github.com/prometheus-community/postgres_exporter/  
По сути это агент, который будет собирать метрики PostgreSQL и отдавать их в Prometheus по локальному endpoint (далее Prometheus опрашивает этот адрес каждые n секунд и складывать в свою time series БД).

---
#### Принцип работы postgres_exporter (равно как и любых других экспортеров для Grafana)
##### Подключение к PG:
postgres_exporter подключается к PostgreSQL через стандартное подключение (обычно TCP-соединение через порт 5432) и гоняет к нему стандантные SQL запросы за метриками.
По правам он использует специально созданного PG пользователя с правами на чтение информации о состоянии сервера (например, членство в роли pg_monitor).
##### Сбор метрик:
postgres_exporter выполняет SQL-запросы к системным представлениям PostgreSQL (например, pg_stat_database, pg_stat_activity, pg_stat_replication, pg_stat_bgwriter, и т.д.).
Метрики, которые собираются, конвертируются в формат Prometheus.  
Здесь важно иметь в виду, что если не устанавливать в PG ряд дополнительных расширений, то набор метрик будет весьма скудным. Для сбора расширенной информации по метрикам, например по раздутию таблиц, работе индексов и пр. надо будет доставлять еще ряд расширений и дополнительно конфигурировать postgres_exporter. В частности полезно поставить следующие расширения:
- pg_stat_statements стандартное расширение для анализа производительности запросов и статистики;
- pg_buffercache для анализа буферов PostgreSQL;  

Надо иметь в виду, что установка дополнительных расширений будет, в определенных ситуациях, отжирать у вас ресурсы самого PostgreSQL, важно следить за этим.
Плюс простая установка этих расширений не приведет к тому что все необходимое начнет собирать сам postgres_exporter. Надо будет добавлять необходимые запросы в его конфигурации, что может отнять у вас дополнительное время.

##### Экспорт метрик:
Сервис postgres_exporter предоставляет HTTP-endpoint (/metrics), с которого Prometheus регулярно собирает метрики (scrape - т.н. скраппинг постоянны через n секунд).

> Похожим образом работают все другие виды экспортеров для prometheus. У Prometheus есть масса различных экспортеров для разных систем, в частности mysql_exporter, mongodb_exporter, redis_exporter и пр.

---  


> **Для сбора метрик самого хоста вам придется дополнительно установить и настроить node_exporter, который работает схожим образом**

Установив postgres_exporter надо настроить пользака, под которым будет происходить сбор метрик мониторинга:
```
CREATE USER postgres_exporter WITH PASSWORD '****';
ALTER USER postgres_exporter SET SEARCH_PATH TO postgres_exporter,pg_catalog;

-- Права доступа для пользователя мониторинга:
GRANT CONNECT ON DATABASE postgres TO postgres_exporter;
GRANT pg_monitor TO postgres_exporter;

```
Далее необходимо настроить запуск postgres_exporter в виде сервиса (systemd)

### 2. Настроить запуск postgres_exporter в виде сервиса (systemd):
Создаем файлик /etc/systemd/system/postgres_exporter.service:
```
[Unit]
Description=Prometheus PostgreSQL Exporter
Wants=network-online.target
After=network-online.target

[Service]
User=postgres
Group=postgres
Type=simple
ExecStart=/usr/local/bin/postgres_exporter \
  --web.listen-address=0.0.0.0:9187 \
  --web.telemetry-path=/metrics \
  --log.level=info \
  --extend.query-path=/etc/postgres_exporter/queries.yaml \
  DATA_SOURCE_NAME="postgresql://postgres_exporter:exporter_password@localhost:5432/postgres?sslmode=disable"

Restart=always

[Install]
WantedBy=multi-user.target

```
Запустите и добавьте в автозагрузку:

```
systemctl daemon-reload
systemctl start postgres_exporter
systemctl enable postgres_exporter
```
Проверьте доступность метрик по адресу:
http://<IP_postgres_exporter>:9187/metrics

### 3. Установить и настроить Prometheus:
Далее нам надо установить [Prometheus](https://prometheus.io/download/) и добавить наш endpoint exporter'а в его конфиг /etc/prometheus/prometheus.yml
```
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'postgres'
    static_configs:
      - targets: ['IP_postgres_exporter:9187']

```

Запускаем Prometheus и добавляет его в автозагрузку:
```
systemctl restart prometheus
systemctl enable prometheus
```

Приверить, что метрики собираются можно зайдя по адресу http://<IP_prometheus>:9090

### 4. Установка Grafana и подключение Prometheus как источника данных:
Следующим шагом требуется установить Grafana и подключить наш Prometheus как источник данных. Для этого:
1. Заходим в Grafana: http://<IP_grafana>:3000
2. Открываем раздел: 
```
Configuration → Data sources → Add data source → Prometheus
```
3. Указываем URL нашего Prometheus
```
http://<IP_prometheus>:9090
```

### 5. Добавим готовые дашборды PostgreSQL в Grafana:
Лучше взять готовые проверенные дашборды:
- Postgres Overview <https://grafana.com/grafana/dashboards/455-postgres-overview/>

![Дашборд Postgres Overview](/images/pg_overview.png)

- PostgreSQL Database <https://grafana.com/grafana/dashboards/9628-postgresql-database/>

![Дашборд PostgreSQL Database](/images/pg_database.png)

Выбираем понравившийся и в Grafana выбираем:

```
Dashboards → Import → вставь ID (9628 или 455) → выбери источник Prometheus.
```

### Минусы и плюсы такого решения
#### Плюсы
- Универсальность архитектуры мониторинга для любых ваших систем. Можно подключаться и мониторить практически все ваши системы в единой архитектуре;
- Можно добавлять новые готовые дашборды или создавать свои;
- Полная бесплатность;
- Индустриальный стандарт;
#### Минусы
- Сложность настройки;
- Нет предиктивной аналитики, вы можете оценивать состояние системы только на "сейчас";
- Нет возможности управления (даже минимальной);
- Нет встроенной аналитики по "тяжелым" запросам. Нет профилировщика таких запросов;

В целом такое решение пригодится только для самого базового мониторинга или для того, кто сам отличный DBA и знает как и что ему нужно добавить в стандартные метрики, чтобы собирать то что нужно.

*Так-же надо понимать какие вам нужны триггеры и оповещения (т.н. Alerting).*

Настраивать их можно как в Grafana ("Alert" → "Create alert rule" на панели) и указав запрос метрики:

```
avg(pg_stat_database_blks_hit / (pg_stat_database_blks_hit + pg_stat_database_blks_read))
```

Далее задать порог, длительность сколько держится условие, список получателей по email, Slack и пр.

Так-же алертинг можно настраивать в Prometheus. Визуально так сделать не получится. Придется прописывать все алерты в yaml файлике и подключать ссылку на него в prometheus.yml

## Готовые opensource решения
Кто не готов разбираться и настраивать все самостоятельно, получив на выходе достаточно скудный функционал, могут попробовать opensource решения разработанные именно для мониторинга PostgreSQL. Далее рассмотрим два самых популярных из них. На самом деле нормальных, развивающихся и бесплатных решений не очень много.

### Percona Monitoring and Management (PMM)

https://www.percona.com/software/database-tools/percona-monitoring-and-management 

Довольно мощное решение для мониторинга PostgreSQL (+ еще MySQL и MongoDB) с базовыми возможностями аналитики запросов, готовыми дашбордами, рекомендациями и аннотациями. Подходит для production-сред с потребностью в централизованном мониторинге и диагностике.

![Percona](/images/percona.png)

#### Архитектура: клиент‑серверная модель

 - PMM Client (устанавливается на каждом сервере с базой данных):
   - Включает pmm-agent (управляет процессами);
   - Экспортеры (например те самые postgres_exporter и node_exporter) для сбора метрик;
   - vmagent (отправка данных);

 - PMM Server (центральный сервер мониторинга):
   - Хранит метрики в VictoriaMetrics;
   - Хранит аналитические данные запросов в ClickHouse;
   - Визуализация и дашборды через Grafana с разработанными Percona шаблонами для нее (как веб морду использует Garafana, да);
   - Включает базовые Query Analytics (QAN) и Percona Advisors (рекомендации по производительности и безопасности);

![PMM Architecture](/images/pmm.png)

#### Возможности

| Возможность                     | Описание |
|--------------------------------|----------|
| Шаблонные дашборды Grafana для PostgreSQL | Включают все основные метрики: CPU, память, I/O, соединения, tuples, индексы, сетевой трафик, процессы и прочее ([подробнее](https://www.percona.com/software/database-tools/percona-monitoring-and-management/postgresql-monitoring)). |
| Анализ запросов      | Анализ SQL-запросов: медленные, ресурсоёмкие, с деталями EXPLAIN и историей выполнения ([подробнее](https://www.percona.com/blog/inspecting-mysql-servers-part-5-percona-monitoring-and-management/)). |
| Аннотации (Annotations)    | Удобная возможность вручную отмечать события (деплой, сбой и т.п.) прямо на графиках для анализа причин проблем ([подробнее](https://www.percona.com/software/database-tools/percona-monitoring-and-management/postgresql-monitoring?utm_source=chatgpt.com)). |
| Percona Advisors          | Автоматический анализ конфигураций и рекомендации по безопасности и производительности ([подробнее](https://www.percona.com/software/database-tools/percona-monitoring-and-management/postgresql-monitoring)). |
| Alerting & управление      | Настройка алертов, возможность бэкапов и восстановления ([подробнее](https://www.percona.com/software/database-tools/percona-monitoring-and-management)). |

#### Минусы и плюсы PMM
##### Плюсы
- "Из коробки" готовые расширенные дашборды для PostgreSQL;
- Включает Query Analytics и Advisors (этого нет в типовой связке Grafana + Prometheus);
- Масштабируемая архитектура;
- Гибкость установки через Docker, Helm и пр.
##### Минусы
- Больше компонентов, сложнее ментейнить все это;
- Менее универсально, только для 3 типов СУБД;
- Сложнее будет докрутить своими метриками по сравнению с Prometheus + Grafana;

### pgAdmin 4

https://www.pgadmin.org/

Не совсем система мониторинга и анализа, скорее веб-GUI для администрирования PostgreSQL (создание объектов, миграции, бэкапы, Query Tool), в котором есть базовые дашборды по состоянию сервера.
Он подходит скорее как удобная админка и точечный мониторинг «здесь-и-сейчас», но не является полноценной системой мониторинга/алертинга.

#### Архитектура

Python (Flask) + psycopg/libpq. Работает в двух режимах - Desktop приложуха и Server (веб-приложение). Данные для виджетов берёт на лету из стандартных pg_stat_* представлений и системных функций PostgreSQL. Метрики не накапливает - только опрашивает и показывает.

![PGAdmin 4 Architecture](/images/pg_admin_arch.png)

#### Возможности

### Возможности

| Возможность | Описание |
| --- | --- |
| Дашборды | «Живые» графики: CPU/IO wait (условное по PostgreSQL, а не хостовые), активные/idle сессии, число блокировок, tuples in/out, чекпоинты, WAL-активность. Данные берутся из `pg_stat_activity`, `pg_stat_database`, `pg_stat_bgwriter`, `pg_stat_replication` и др. |
| Activity / Locks / Sessions | Просмотр текущих запросов, планов, блокировок, ожиданий, отмена/terminate процессов. |
| Query Tool | SQL редактор, EXPLAIN/EXPLAIN ANALYZE, автоформатирование, история запросов. |
| Maintenance | VACUUM/REINDEX/ANALYZE/CLUSTER, бэкапы/восстановление (обёртки над `pg_dump/pg_restore`). |
| Управление СУБД | Роли/права, таблицы, индексы, партиции, расширения (в т.ч. `pg_stat_statements`). |
| Аутентификация/Роли в UI | Учетки самого pgAdmin, группы, хранение подключений, SSO (LDAP/OAuth) |

#### Минусы и плюсы pgAdmin 4
##### Плюсы
- Работа без агентов: подключается напрямую к PostgreSQL; достаточно сетевого доступа и ролей;
- Продвинутые админ функции: Query Tool, EXPLAIN, бэкапы, управление объектами и ролями;
- Простая установка: пакеты для Win/macOS/Linux, Docker-образ, Helm-чарт; работает и как Desktop, и как Web.
##### Минусы
- Нет никаких хостовых метрик т.е. аналитика совсем не полная;
- Не система мониторинга: нет долговременного хранения метрик/серий (показывают текущее/недавнее состояние, без ретроспективной аналитики)
- Нет алертинга, «предиктивной» аналитики, советников и готовых SLO/alerts;
- Ограниченные дашборды по сравнению с PMM/Grafana; нельзя «докрутить» экспортеры/свои метрики как в Prometheus.

В целом подходит для малых/средних инсталляций, где нет требований к ретроспективному мониторингу и алертингу, ну или использовать как дополнение к PMM/Prometheus-стэку если есть желание городить зоопарк.

## Платные коммерческие решения

### pganalyze

### Tantor Platform
Все в одном и не только мониторинг
bla bla bla
